<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Image Processing Project</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 20px;
            padding: 0;
            background-color: #f4f4f4;
        }
        h1, h2 {
            color: #333;
        }
        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            background: #fff;
            border-radius: 8px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        }
        .code-container {
            background: #2e2e2e;
            color: #f8f8f2;
            padding: 10px;
            border-radius: 4px;
            overflow-x: auto; /* Ensure horizontal scrolling */
            white-space: nowrap; /* Prevent wrapping */
            margin-bottom: 20px;
            max-width: 100%; /* Adjust width to fit the container */
        }
        code {
            display: block;
            white-space: pre;
        }
        .section {
            margin-bottom: 20px;
        }
        .section h2 {
            margin-top: 0;
        }
        .image-container {
            text-align: center; /* Center the image container */
            margin: 20px 0; /* Add some margin around the images */
        }
        .image-container img {
            max-width: 50%; /* Reduce the width to 50% of the container */
            height: auto; /* Maintain aspect ratio */
            max-height: 200px; /* Set a smaller max height */
            object-fit: cover; /* Ensure the image covers the container without distortion */
            border: 1px solid #ddd; /* Optional: add a border for better visibility */
            border-radius: 8px; /* Optional: round the corners of the image */
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>CS180 Project 1: Images of the Russian Empire</h1>
        <h2>Overview</h2>
        <p>Sergei Mikhailovich Prokudin-Gorskii (1863-1944) was a pioneering photographer who, 
            in the early 20th century, utilized a unique color photography technique. 
            He captured thousands of color photographs across the Russian Empire using a method that 
            involved taking three separate exposures of each scene through red, green, and blue filters on glass plates. 
            Despite his vision of projecting these images to educate Russian children, his plans were never realized, 
            and he left Russia in 1918. Fortunately, his collection of RGB glass plate negatives survived and was later digitized 
            by the Library of Congress (LoC), making them available online. The goal of this project is to process the digitized 
            Prokudin-Gorskii glass plate images and reconstruct them into full-color photographs. 
            This involves extracting and aligning the three color channel images (red, green, and blue) 
            to produce a composite RGB image with minimal visual artifacts.</p>
        
        <h2>Implementation</h2>
        <div class="section">
            <h3>Imports and Paths</h3>
            <div class="code-container">
                <code>
import numpy as np
import skimage as sk
import skimage.io as skio
import matplotlib.pyplot as plt
import os

data_folder = '/Users/raiyanausaf14/Desktop/CS180/project1/data/'
output_folder = '/Users/raiyanausaf14/Desktop/CS180/project1/output/'
                </code>
            </div>
        </div>

        <div class="section">
            <h3>Normalized Cross Correlation</h3>
            <div class="code-container">
                <code>
def normalized_crosscorrelation(image1, image2):
    norm1 = np.linalg.norm(image1, 'fro')
    norm2 = np.linalg.norm(image2, 'fro')
    image1 = image1 / norm1
    image2 = image2 / norm2
    return np.sum(image1 * image2)
                </code>
            </div>
            <p>Used a Forbenius Norm, then normalized the respective matricies. Then returned the matrix dot product (elementwise).</p>
        </div>

        <div class="section">
            <h3>Finding the Best Image Displacement</h3>
            <div class="code-container">
                <code>
def find_best_shift(channel, reference, max_shift=15):
    best_score = -float('inf')
    best_dx = 0
    best_dy = 0

    for dx in range(-max_shift, max_shift + 1):
        for dy in range(-max_shift, max_shift + 1):
            shifted_channel = np.roll(channel, shift=(dy, dx), axis=(0, 1))
            score = normalized_crosscorrelation(reference, shifted_channel)
            
            if score > best_score:
                best_score = score
                best_dx = dx
                best_dy = dy

    return best_dx, best_dy
                </code>
            </div>
            <p>Used np.roll to make the shifts across the columns and rolls, and found the best score using the normalized cross correlation</p>
        </div>
        
        <div class="section">
            <h3>Brightness Problem</h3>
            <div class="code-container">
                <code>
def normalize_brightness(channel, reference):
    ref_mean = np.mean(reference)
    ref_std = np.std(reference)

    ch_mean = np.mean(channel)
    ch_std = np.std(channel)

    # Normalize the input channel to match the reference channel's mean and std
    normalized_channel = (channel - ch_mean) * (ref_std / ch_std) + ref_mean

    return normalized_channel
                </code>
            </div>
            <p>The Normalized Cross Correlation was not an effective metric especially since the brightness was not the same on some pictures, 
                to combat this by shifting the mean brightness and standard deviation to match that of the blue channel.
            </p>
        </div>

        <div class="section">
            <h3>Image Pyramid</h3>
            <div class="code-container">
                <code>
def gaussian_filter(image, sigma):
    return skf.gaussian(image, sigma=sigma, mode='reflect')

def resize_image(image, scale):
    return skt.rescale(image, scale, mode='reflect', anti_aliasing=True)

def gaussian_pyramid(image, levels, sigma):
    pyramid = [image]
    for i in range(1, levels):
        image = gaussian_filter(image, sigma)
        image = resize_image(image, 0.5)
        pyramid.append(image)
    return pyramid

def find_best_shift_pyramid(channel, reference, max_shift=15, pyramid_levels=4, sigma=1):
    channel_pyramid = gaussian_pyramid(channel, pyramid_levels, sigma)
    reference_pyramid = gaussian_pyramid(reference, pyramid_levels, sigma)

    best_dx, best_dy = 0, 0

    for level in range(pyramid_levels - 1, -1, -1):
        best_dx *= 2
        best_dy *= 2
        
        channel_level = np.roll(channel_pyramid[level], shift=(best_dy, best_dx), axis=(0, 1))
        reference_level = reference_pyramid[level]
        
        dx, dy = find_best_shift(channel_level, reference_level, max_shift=max_shift)
        
        best_dx += dx
        best_dy += dy

    return best_dx, best_dy
                </code>
            </div>
            <p>Using an image pyramind helps us achieve the deseriable minute average per picture. We use the built in resizing and gaussian filter in skf, but
                as mentioned in the project specifics, we implement the pyramid scheme from scratch. At each level we apply a gaussian filter and resize the shape by half.
                By using the image pyramid, we leverage results of the smaller, downstreamed images to build back up. There is more code, but most of that is just bringing
                all the functions together to process the function and save the results.
            </p>
        </div>

        <div class="section"></div>
            <h3>B&W Edge Detection</h3>
            <div class="code-container">
                <code>
def process_image(image_path):
    im = skio.imread(image_path)
    im = sk.img_as_float(im)

    # Divide the image into color channels
    height = np.floor(im.shape[0] / 3.0).astype(int)
    b = im[:height]
    g = im[height: 2*height]
    r = im[2*height: 3*height]

    # Normalize brightness
    g_normalized = normalize_brightness(g, b)
    r_normalized = normalize_brightness(r, b)

    # Apply edge detection
    b_edges = detect_edges(b)
    g_edges = detect_edges(g_normalized)
    r_edges = detect_edges(r_normalized)

    # Find the best shifts after normalization and edge detection using pyramid method
    best_dx_g, best_dy_g = find_best_shift_pyramid(g_edges, b_edges, max_shift=15, pyramid_levels=4)
    best_dx_r, best_dy_r = find_best_shift_pyramid(r_edges, b_edges, max_shift=15, pyramid_levels=4)

    # Align the channels
    aligned_g = np.roll(g_normalized, shift=(best_dy_g, best_dx_g), axis=(0, 1))
    aligned_r = np.roll(r_normalized, shift=(best_dy_r, best_dx_r), axis=(0, 1))

    # Stack the channels in RGB order (flip from BGR)
    color_image = np.stack((aligned_r, aligned_g, b), axis=-1)

    return color_image

def detect_edges(image):
    # Use Canny edge detection
    edges = skfeat.canny(image, sigma=1)
    return edges.astype(float)

def find_best_shift_pyramid(channel, reference, max_shift=15, pyramid_levels=4, sigma=1):
    channel_pyramid = gaussian_pyramid(channel, pyramid_levels, sigma)
    reference_pyramid = gaussian_pyramid(reference, pyramid_levels, sigma)

    best_dx, best_dy = 0, 0

    for level in range(pyramid_levels - 1, -1, -1):
        best_dx *= 2
        best_dy *= 2
        
        channel_level = np.roll(channel_pyramid[level], shift=(best_dy, best_dx), axis=(0, 1))
        reference_level = reference_pyramid[level]
        
        dx, dy = find_best_shift(channel_level, reference_level, max_shift=max_shift)
        
        best_dx += dx
        best_dy += dy
    print(best_dx, best_dy)
    return best_dx, best_dy
                </code>
            </div>
            <p>Some images such as the Emir one were really struggling to align, so for my B&W I decided to use edge detection to align them.
                While the code is abstract, I did look at how it works at under the hood. A Canny Edge detection first starts off with a Gaussian Smoothing,
                which allows us to reduce noise in the image (outliers that might be interpreted as edges). Then we use gradients of pixels relative to the neighboring
                pixels to determine the edges as it tells us how sharp pixel color/brightness change, indicating an edge. The code is updated to perform the alignment relative to the edges with
                still usign image pyramid scheme.
            </p>


        <h2>Results</h2>
        <p> I have also attatched all the images with their corresponding best green filter shift (with respect to blue) and red filter shift (with respect to blue).
        </p>

        <div class="section">
            <h3>Image Gallery</h3>
            <div class="image-container">
                <img src="./output/aligned_emir.jpg">
                <figcaption>(23, 49) Green & (40, 107) Red</figcaption>
                <img src="./output/aligned_monastery.jpg">
                <figcaption>(2, -3) Green & (2, 3) Red</figcaption>
                <img src="./output/aligned_church.jpg">
                <figcaption>(4, 25) Green & (-4, 58) Red</figcaption>
                <img src="./output/aligned_three_generations.jpg">
                <figcaption>(11, 56) Green & (7, 111) Red</figcaption>
                <img src="./output/aligned_melons.jpg">
                <figcaption>(9, 89) Green & (11, 182) Red</figcaption>
                <img src="./output/aligned_onion_church.jpg">
                <figcaption>(24, 52) Green & (34, 107) Red</figcaption>
                <img src="./output/aligned_train.jpg">
                <figcaption>(2, 48) Green & (29, 85) Red</figcaption>
                <img src="./output/aligned_tobolsk.jpg">
                <figcaption>(2, 3) Green & (3, 6) Red</figcaption>
                <img src="./output/aligned_icon.jpg">
                <figcaption>(16, 38) Green & (22, 90) Red</figcaption>
                <img src="./output/aligned_cathedral.jpg">
                <figcaption>(2, 5) Green & (3, 12) Red</figcaption>
                <img src="./output/aligned_self_portrait.jpg">
                <figcaption>(29, 77) Green & (37, 175) Red</figcaption>
                <img src="./output/aligned_harvesters.jpg">
                <figcaption>(18, 60) Green & (11, 117) Red</figcaption>
                <img src="./output/aligned_sculpture.jpg">
                <figcaption>(-11, 33) Green & (-27, 140) Red</figcaption>
                <img src="./output/aligned_lady.jpg">
                <figcaption>(10, 56) Green & (13, 120) Red</figcaption>
            </div>
        </div>
    </div>
</body>
</html>
